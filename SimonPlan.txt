Here is the plan for the simplest benchmark (Volatility Calibration):

I. Concerning Scripts and Clean Implementation (Ready by 3rd of April'14)

    1. Scripts to build and to run benchmarks.
        - Default should be build/run ALL benchmarks on ALL datasets
            on ALL provided implementations, i.e., Haskell, Sequential C++,
            multicore C++ (OpenmMP), GPU C++ (OpenCL), on all datasets.

        - We also need a way to select options, e.g., build/run only these
             benchmarks, only the C++ multicore and GPU versions, and    
             only on the medium and largest datasets.

    2. DONE! Decide and implement what the REPORT file should be
        (probably a summary of runtimes for the selected options)
   
        The technology for the Input Datasets ok (?)

    3. DONE! Validation via diff on output file.  One possibility is to
        model the acceptable error in the current implementation to the
        number of digits that are to be printed after the dot.

    4. A clean, simple, map-reduce-like Haskell implementation for the
        Volatility Calibration benchmark.   Comments when the `fold/scan'
        has parallel semantics and when not, i.e., when the operator is
        associative.
        Meeting on Wednesday and fix that in three hours. The only
        challenge there is TRIDAG.

II. Concerning the Parallel GPU version of Volatility Calibration (Ready by ?)

    1. Making the code generic such that to work/validate at least for
        Mac, Linux OpSys and AMD and NVIDIA GPUS. For example
        parameterize the WARP to 16 for AMD and 32 for NVIDIA, and tune
        for AMD -- Cosmin, Martin.

    2. Design a combined version that models the tradeoff between
        application's and hardware's degree of parallelism, i.e., efficiently
        sequentialising the innermost scan when the two outermost loops
        offer enough parallelism to fully utilize the hardware. This cost
        model should be expressed as an arbitrary-shaped predicate
        that discriminates between the two versions of the code.   -- Cosmin

    3. Currently the fully parallelized version, i.e., VectAll works only when
        0 < NUM_X, NUM_Y <= 256 or so.   This is because the implementation
        of the segmented scan assumes that the segment ``fits'' into a local
        workgroup, due to efficiency reasons.

        Extend the implementation with a global (regular) segmented scan,
        i.e., arbitrarily large NUM_X and NUM_Y.

        Separate basic blocks such as segmented scan (global/local) into
        a OpenCL-library file(s) usable from all benchmarks.  -- Cosmin

    4. ??? Profiling the GPU efficiency: find a way to profile the hardware counters,
        and find some information related to the reasons why we are not close
        to peak performance. E.g., Is the application memory bound rather than
        computationally bound? Is there significant divergence overhead?
        Is the hardware occupancy limited by register (fast memory) pressure
        that decreases the ability of the system to hide latency, etc. 

